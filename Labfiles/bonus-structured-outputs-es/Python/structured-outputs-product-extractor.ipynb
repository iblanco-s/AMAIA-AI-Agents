{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Outputs con Microsoft Agent Framework\n",
    "\n",
    "## Descripción\n",
    "\n",
    "En este ejercicio, aprenderás a crear agentes que producen **salidas estructuradas** en forma de objetos JSON que se ajustan a un esquema específico. Esto es fundamental cuando necesitas que la IA genere datos en un formato predecible y procesable.\n",
    "\n",
    "### Casos de uso:\n",
    "- Extracción de información clave de textos\n",
    "- Generación de objetos Python desde texto\n",
    "- Validación y transformación de datos\n",
    "- Análisis de documentos con formato consistente\n",
    "- Procesamiento de formularios y tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración inicial\n",
    "\n",
    "### Cargar librerías\n",
    "\n",
    "Importamos las bibliotecas necesarias. Usaremos **Pydantic** para definir los esquemas de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "\n",
    "# GitHub Models client configuration\n",
    "MODEL_NAME = os.getenv(\"GITHUB_MODEL\", \"openai/gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función auxiliar común\n",
    "\n",
    "Esta función auxiliar será utilizada por los 2 ejercicios para ejecutar el agente con structured outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función auxiliar definida correctamente\n"
     ]
    }
   ],
   "source": [
    "async def run_structured_agent(\n",
    "    instructions: str,\n",
    "    user_input: str,\n",
    "    response_format: type[BaseModel],\n",
    "    agent_name: str = \"structured_agent\"\n",
    ") -> BaseModel:\n",
    "    \"\"\"\n",
    "    Función auxiliar para ejecutar un agente con salida estructurada.\n",
    "    \n",
    "    Args:\n",
    "        instructions: Instrucciones para el agente\n",
    "        user_input: Entrada del usuario\n",
    "        response_format: Clase Pydantic que define el formato de salida\n",
    "        agent_name: Nombre del agente\n",
    "        \n",
    "    Returns:\n",
    "        Instancia del modelo Pydantic con los datos extraídos\n",
    "    \"\"\"\n",
    "    client = OpenAIChatClient(\n",
    "        model_id=MODEL_NAME,\n",
    "        api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    "        base_url=\"https://models.github.ai/inference\"\n",
    "    )\n",
    "    \n",
    "    async with ChatAgent(\n",
    "        chat_client=client,\n",
    "        name=agent_name,\n",
    "        instructions=instructions,\n",
    "        response_format=response_format\n",
    "    ) as agent:\n",
    "        response = await agent.run([user_input])\n",
    "        # The AgentRunResponse object has the 'value' attribute containing the JSON dictionary\n",
    "        return response_format.model_validate(response.value)\n",
    "\n",
    "\n",
    "print(\"Función auxiliar definida correctamente\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token encontrado: ghu_yddGIV...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Verificar si existe el token\n",
    "token = os.environ.get(\"GITHUB_TOKEN\")\n",
    "if token:\n",
    "    print(f\"Token encontrado: {token[:10]}...\")  # Muestra solo los primeros caracteres\n",
    "else:\n",
    "    print(\"❌ GITHUB_TOKEN no está configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 1: Extracción de información clave de texto\n",
    "\n",
    "En este ejercicio, extraeremos información estructurada de un artículo de noticias. El agente identificará los elementos clave del texto y los organizará en un formato JSON predefinido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceResponseException",
     "evalue": "<class 'agent_framework.openai._chat_client.OpenAIChatClient'> service failed to complete the prompt: Unauthorized",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\agent_framework\\openai\\_chat_client.py:76\u001b[39m, in \u001b[36mOpenAIBaseChatClient._inner_get_response\u001b[39m\u001b[34m(self, messages, chat_options, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_response(\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m client.chat.completions.create(stream=\u001b[38;5;28;01mFalse\u001b[39;00m, **options_dict), chat_options\n\u001b[32m     77\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BadRequestError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:2585\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2584\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2585\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2587\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2588\u001b[39m         {\n\u001b[32m   2589\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2590\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2591\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2592\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2593\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2594\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2595\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2596\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2597\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2598\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2599\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2600\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2601\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2602\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2603\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2604\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2605\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2606\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2607\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2608\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2609\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2610\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2611\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2612\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2613\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2614\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2615\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2616\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2617\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2618\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2619\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2620\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2621\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   2622\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2623\u001b[39m         },\n\u001b[32m   2624\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2625\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2626\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2627\u001b[39m     ),\n\u001b[32m   2628\u001b[39m     options=make_request_options(\n\u001b[32m   2629\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2630\u001b[39m     ),\n\u001b[32m   2631\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2632\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2633\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2634\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1794\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1791\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1792\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1793\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1794\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1594\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1593\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1594\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1596\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Unauthorized",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceResponseException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     31\u001b[39m instructions_article = \u001b[33m\"\"\"\u001b[39m\u001b[33mEres un experto en análisis de contenido y extracción de información.\u001b[39m\n\u001b[32m     32\u001b[39m \n\u001b[32m     33\u001b[39m \u001b[33mAnaliza el texto proporcionado y extrae:\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m \n\u001b[32m     42\u001b[39m \u001b[33mSé preciso y objetivo. Responde SOLO con el JSON estructurado.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Run the agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m article_info = \u001b[38;5;28;01mawait\u001b[39;00m run_structured_agent(\n\u001b[32m     46\u001b[39m     instructions=instructions_article,\n\u001b[32m     47\u001b[39m     user_input=article_text,\n\u001b[32m     48\u001b[39m     response_format=ArticleInfo,\n\u001b[32m     49\u001b[39m     agent_name=\u001b[33m\"\u001b[39m\u001b[33marticle_extractor\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     50\u001b[39m )\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mrun_structured_agent\u001b[39m\u001b[34m(instructions, user_input, response_format, agent_name)\u001b[39m\n\u001b[32m     19\u001b[39m client = OpenAIChatClient(\n\u001b[32m     20\u001b[39m     model_id=MODEL_NAME,\n\u001b[32m     21\u001b[39m     api_key=os.environ[\u001b[33m\"\u001b[39m\u001b[33mGITHUB_TOKEN\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     22\u001b[39m     base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://models.github.ai/inference\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m ChatAgent(\n\u001b[32m     26\u001b[39m     chat_client=client,\n\u001b[32m     27\u001b[39m     name=agent_name,\n\u001b[32m     28\u001b[39m     instructions=instructions,\n\u001b[32m     29\u001b[39m     response_format=response_format\n\u001b[32m     30\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agent:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m agent.run([user_input])\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# The AgentRunResponse object has the 'value' attribute containing the JSON dictionary\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_format.model_validate(response.value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\agent_framework\\_middleware.py:1249\u001b[39m, in \u001b[36muse_agent_middleware.<locals>.middleware_enabled_run\u001b[39m\u001b[34m(self, messages, thread, middleware, **kwargs)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m AgentRunResponse()\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# No middleware, execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_run(\u001b[38;5;28mself\u001b[39m, normalized_messages, thread=thread, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\agent_framework\\observability.py:1106\u001b[39m, in \u001b[36m_trace_agent_run.<locals>.trace_run\u001b[39m\u001b[34m(self, messages, thread, **kwargs)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m   1105\u001b[39m     \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_func(\u001b[38;5;28mself\u001b[39m, messages=messages, thread=thread, **kwargs)\n\u001b[32m   1107\u001b[39m attributes = _get_span_attributes(\n\u001b[32m   1108\u001b[39m     operation_name=OtelAttr.AGENT_INVOKE_OPERATION,\n\u001b[32m   1109\u001b[39m     provider_name=provider_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1115\u001b[39m     **kwargs,\n\u001b[32m   1116\u001b[39m )\n\u001b[32m   1117\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _get_span(attributes=attributes, span_name_attribute=OtelAttr.AGENT_NAME) \u001b[38;5;28;01mas\u001b[39;00m span:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\agent_framework\\_agents.py:871\u001b[39m, in \u001b[36mChatAgent.run\u001b[39m\u001b[34m(self, messages, thread, allow_multiple_tool_calls, frequency_penalty, logit_bias, max_tokens, metadata, model_id, presence_penalty, response_format, seed, stop, store, temperature, tool_choice, tools, top_p, user, additional_chat_options, **kwargs)\u001b[39m\n\u001b[32m    849\u001b[39m     final_tools.extend(mcp_server.functions)\n\u001b[32m    851\u001b[39m co = run_chat_options & ChatOptions(\n\u001b[32m    852\u001b[39m     model_id=model_id,\n\u001b[32m    853\u001b[39m     conversation_id=thread.service_thread_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     **(additional_chat_options \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    870\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chat_client.get_response(messages=thread_messages, chat_options=co, **kwargs)\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._update_thread_with_type_and_conversation_id(thread, response.conversation_id)\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Ensure that the author name is set for each message in the response.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\agent_framework\\_tools.py:1567\u001b[39m, in \u001b[36m_handle_function_calls_response.<locals>.decorator.<locals>.function_invocation_wrapper\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1564\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1565\u001b[39m     _replace_approval_contents_with_results(prepped_messages, fcc_todo, approved_function_results)\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, messages=prepped_messages, **kwargs)\n\u001b[32m   1568\u001b[39m \u001b[38;5;66;03m# if there are function calls, we will handle them first\u001b[39;00m\n\u001b[32m   1569\u001b[39m function_results = {\n\u001b[32m   1570\u001b[39m     it.call_id \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m response.messages[\u001b[32m0\u001b[39m].contents \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(it, FunctionResultContent)\n\u001b[32m   1571\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\agent_framework\\observability.py:836\u001b[39m, in \u001b[36m_trace_get_response.<locals>.decorator.<locals>.trace_get_response\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m OBSERVABILITY_SETTINGS\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OBSERVABILITY_SETTINGS.ENABLED:\n\u001b[32m    835\u001b[39m     \u001b[38;5;66;03m# If model_id diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\n\u001b[32m    837\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    838\u001b[39m         messages=messages,\n\u001b[32m    839\u001b[39m         **kwargs,\n\u001b[32m    840\u001b[39m     )\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtoken_usage_histogram\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.additional_properties:\n\u001b[32m    842\u001b[39m     \u001b[38;5;28mself\u001b[39m.additional_properties[\u001b[33m\"\u001b[39m\u001b[33mtoken_usage_histogram\u001b[39m\u001b[33m\"\u001b[39m] = _get_token_usage_histogram()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\agent_framework\\_middleware.py:1367\u001b[39m, in \u001b[36muse_chat_middleware.<locals>.middleware_enabled_get_response\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m   1365\u001b[39m \u001b[38;5;66;03m# If no chat middleware, use original method\u001b[39;00m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chat_middleware_list:\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m original_get_response(\u001b[38;5;28mself\u001b[39m, messages, **kwargs)\n\u001b[32m   1369\u001b[39m \u001b[38;5;66;03m# Create pipeline and execute with middleware\u001b[39;00m\n\u001b[32m   1370\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOptions\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\agent_framework\\_clients.py:577\u001b[39m, in \u001b[36mBaseChatClient.get_response\u001b[39m\u001b[34m(self, messages, frequency_penalty, logit_bias, max_tokens, metadata, model_id, presence_penalty, response_format, seed, stop, store, temperature, tool_choice, tools, top_p, user, additional_properties, **kwargs)\u001b[39m\n\u001b[32m    574\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_tool_choice(chat_options=chat_options)\n\u001b[32m    576\u001b[39m filtered_kwargs = \u001b[38;5;28mself\u001b[39m._filter_internal_kwargs(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_response(messages=prepped_messages, chat_options=chat_options, **filtered_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\inigo.blanco\\OneDrive - GFI\\code\\training\\iblanco-ai-agents\\.venv\\Lib\\site-packages\\agent_framework\\openai\\_chat_client.py:89\u001b[39m, in \u001b[36mOpenAIBaseChatClient._inner_get_response\u001b[39m\u001b[34m(self, messages, chat_options, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m     85\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     86\u001b[39m         inner_exception=ex,\n\u001b[32m     87\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m     90\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     91\u001b[39m         inner_exception=ex,\n\u001b[32m     92\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n",
      "\u001b[31mServiceResponseException\u001b[39m: <class 'agent_framework.openai._chat_client.OpenAIChatClient'> service failed to complete the prompt: Unauthorized"
     ]
    }
   ],
   "source": [
    "# Define the schema for article information\n",
    "class ArticleInfo(BaseModel):\n",
    "    \"\"\"Información estructurada extraída de un artículo\"\"\"\n",
    "    title: str = Field(description=\"Título principal del artículo\")\n",
    "    summary: str = Field(description=\"Resumen breve del contenido\")\n",
    "    main_topic: str = Field(description=\"Tema principal\")\n",
    "    key_points: List[str] = Field(description=\"Puntos clave mencionados\")\n",
    "    entities: List[str] = Field(description=\"Personas, organizaciones o lugares mencionados\")\n",
    "    date_mentioned: Optional[str] = Field(None, description=\"Fecha mencionada en el artículo\")\n",
    "    sentiment: str = Field(description=\"Sentimiento general: positivo, neutral o negativo\")\n",
    "\n",
    "\n",
    "# Example text: news article\n",
    "article_text = \"\"\"\n",
    "La Unión Europea anunció ayer un ambicioso plan para reducir las emisiones de carbono \n",
    "en un 55% para el año 2030. La presidenta de la Comisión Europea, Ursula von der Leyen, \n",
    "presentó el paquete de medidas en una conferencia de prensa en Bruselas.\n",
    "\n",
    "El plan incluye inversiones masivas en energías renovables, con un enfoque especial en \n",
    "energía solar y eólica. Se destinarán 750 mil millones de euros para la transición verde. \n",
    "Además, se implementarán nuevas regulaciones para la industria automotriz, exigiendo que \n",
    "todos los vehículos nuevos sean eléctricos para 2035.\n",
    "\n",
    "Los países miembros como Alemania, Francia y España han expresado su apoyo a la iniciativa. \n",
    "Sin embargo, algunos estados del este de Europa han manifestado preocupaciones sobre los \n",
    "costos de implementación. Expertos ambientalistas consideran que este es un paso crucial \n",
    "en la lucha contra el cambio climático.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions for the agent\n",
    "instructions_article = \"\"\"Eres un experto en análisis de contenido y extracción de información.\n",
    "\n",
    "Analiza el texto proporcionado y extrae:\n",
    "- Un título descriptivo\n",
    "- Un resumen conciso\n",
    "- El tema principal\n",
    "- Los puntos clave más importantes\n",
    "- Nombres de personas, organizaciones y lugares\n",
    "- Fechas mencionadas\n",
    "- El sentimiento general del artículo\n",
    "\n",
    "Sé preciso y objetivo. Responde SOLO con el JSON estructurado.\"\"\"\n",
    "\n",
    "# Run the agent\n",
    "article_info = await run_structured_agent(\n",
    "    instructions=instructions_article,\n",
    "    user_input=article_text,\n",
    "    response_format=ArticleInfo,\n",
    "    agent_name=\"article_extractor\"\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*70)\n",
    "print(\"EJERCICIO 1: EXTRACCIÓN DE INFORMACIÓN CLAVE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nResultado estructurado:\\n\")\n",
    "print(f\"Título: {article_info.title}\")\n",
    "print(f\"Tema: {article_info.main_topic}\")\n",
    "print(f\"Sentimiento: {article_info.sentiment}\")\n",
    "print(f\"\\nResumen:\\n{article_info.summary}\")\n",
    "print(f\"\\nPuntos clave:\")\n",
    "for i, point in enumerate(article_info.key_points, 1):\n",
    "    print(f\"  {i}. {point}\")\n",
    "print(f\"\\nEntidades mencionadas: {', '.join(article_info.entities)}\")\n",
    "if article_info.date_mentioned:\n",
    "    print(f\"Fecha: {article_info.date_mentioned}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"\\nJSON completo:\")\n",
    "print(json.dumps(article_info.model_dump(), indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 2: Generación de objetos Python desde texto\n",
    "\n",
    "En este ejercicio, crearemos objetos Python completos a partir de descripciones en lenguaje natural. El agente generará instancias de clases con tipos de datos nativos de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes to represent employees\n",
    "class Address(BaseModel):\n",
    "    \"\"\"Dirección física\"\"\"\n",
    "    street: str = Field(description=\"Calle y número\")\n",
    "    city: str = Field(description=\"Ciudad\")\n",
    "    postal_code: str = Field(description=\"Código postal\")\n",
    "    country: str = Field(description=\"País\")\n",
    "\n",
    "\n",
    "class Department(str, Enum):\n",
    "    \"\"\"Departamentos de la empresa\"\"\"\n",
    "    ENGINEERING = \"engineering\"\n",
    "    SALES = \"sales\"\n",
    "    MARKETING = \"marketing\"\n",
    "    HR = \"human_resources\"\n",
    "    FINANCE = \"finance\"\n",
    "    OPERATIONS = \"operations\"\n",
    "\n",
    "\n",
    "class Employee(BaseModel):\n",
    "    \"\"\"Información de un empleado\"\"\"\n",
    "    employee_id: int = Field(description=\"ID único del empleado\")\n",
    "    first_name: str = Field(description=\"Nombre\")\n",
    "    last_name: str = Field(description=\"Apellido\")\n",
    "    email: str = Field(description=\"Email corporativo\")\n",
    "    phone: str = Field(description=\"Teléfono de contacto\")\n",
    "    department: Department = Field(description=\"Departamento\")\n",
    "    position: str = Field(description=\"Cargo o posición\")\n",
    "    salary: float = Field(description=\"Salario anual en euros\")\n",
    "    hire_date: str = Field(description=\"Fecha de contratación (YYYY-MM-DD)\")\n",
    "    address: Address = Field(description=\"Dirección del empleado\")\n",
    "    is_remote: bool = Field(description=\"¿Trabaja de forma remota?\")\n",
    "    skills: List[str] = Field(description=\"Habilidades técnicas o profesionales\")\n",
    "\n",
    "\n",
    "# Employee description in free text\n",
    "employee_description = \"\"\"\n",
    "María Carmen García López fue contratada el 15 de marzo de 2023 como Ingeniera Senior \n",
    "de Software. Su ID de empleado es 10542. Trabaja en el departamento de ingeniería con \n",
    "un salario anual de 65000 euros.\n",
    "\n",
    "Puede contactarla en mc.garcia@empresa.com o al teléfono +34 666 123 456. \n",
    "Actualmente trabaja desde Madrid de forma remota. Su dirección registrada es \n",
    "Calle Gran Vía 28, Madrid, código postal 28013, España.\n",
    "\n",
    "María tiene experiencia en Python, JavaScript, React, Django y bases de datos SQL. \n",
    "También domina metodologías ágiles y arquitectura de microservicios.\n",
    "\"\"\"\n",
    "\n",
    "# Instructions for the agent\n",
    "instructions_employee = \"\"\"Eres un experto en procesamiento de información de recursos humanos.\n",
    "\n",
    "Analiza la descripción del empleado y extrae TODA la información disponible.\n",
    "\n",
    "Reglas importantes:\n",
    "- El employee_id debe ser numérico\n",
    "- El email debe tener formato válido\n",
    "- El departamento debe ser uno de los valores válidos del enum\n",
    "- La fecha debe estar en formato YYYY-MM-DD\n",
    "- El salario debe ser numérico (sin símbolos de moneda)\n",
    "- Identifica correctamente si trabaja remoto o presencial\n",
    "\n",
    "Responde SOLO con el JSON estructurado.\"\"\"\n",
    "\n",
    "# Run the agent\n",
    "employee = await run_structured_agent(\n",
    "    instructions=instructions_employee,\n",
    "    user_input=employee_description,\n",
    "    response_format=Employee,\n",
    "    agent_name=\"employee_parser\"\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*70)\n",
    "print(\"EJERCICIO 2: GENERACIÓN DE OBJETOS PYTHON\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nObjeto Employee creado:\\n\")\n",
    "print(f\"ID: {employee.employee_id}\")\n",
    "print(f\"Nombre completo: {employee.first_name} {employee.last_name}\")\n",
    "print(f\"Email: {employee.email}\")\n",
    "print(f\"Teléfono: {employee.phone}\")\n",
    "print(f\"Departamento: {employee.department.value}\")\n",
    "print(f\"Posición: {employee.position}\")\n",
    "print(f\"Salario: {employee.salary:,.2f} EUR\")\n",
    "print(f\"Fecha de contratación: {employee.hire_date}\")\n",
    "print(f\"Trabajo remoto: {'Sí' if employee.is_remote else 'No'}\")\n",
    "print(f\"\\nDirección:\")\n",
    "print(f\"  {employee.address.street}\")\n",
    "print(f\"  {employee.address.postal_code} {employee.address.city}\")\n",
    "print(f\"  {employee.address.country}\")\n",
    "print(f\"\\nHabilidades: {', '.join(employee.skills)}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"\\nTipo de objeto:\", type(employee))\n",
    "print(\"Es instancia de Employee:\", isinstance(employee, Employee))\n",
    "print(\"\\nJSON serializado:\")\n",
    "print(json.dumps(employee.model_dump(), indent=2, ensure_ascii=False))\n",
    "\n",
    "# Demonstrate that we can use the object in Python code\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"\\nEjemplo de uso en código Python:\")\n",
    "print(f\"Salario mensual: {employee.salary / 12:,.2f} EUR\")\n",
    "print(f\"Email dominio: {employee.email.split('@')[1]}\")\n",
    "print(f\"Años de experiencia requerida: {len(employee.skills)} habilidades registradas\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
